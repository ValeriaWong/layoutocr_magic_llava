# Magic_LlaVA - æ³•å¾‹è¯æ®æå–ä¸æ€»ç»“å¤šæ¨¡æ€å¤§æ¨¡å‹





## ğŸ“– ç›®å½•

- [Magic_LlaVA - æ³•å¾‹è¯æ®æå–ä¸æ€»ç»“å¤šæ¨¡æ€å¤§æ¨¡å‹](#Magic_LlaVA - æ³•å¾‹è¯æ®æå–ä¸æ€»ç»“å¤šæ¨¡æ€å¤§æ¨¡å‹)
  - [ğŸ“„ æ¶æ„å›¾](#-æ¶æ„å›¾)
  - [ğŸ‰ News](#-News)
  - [ğŸ“ ç®€ä»‹](#-ç®€ä»‹)
  - [ğŸ“Œ å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
    - [1. ç®—åŠ›è¦æ±‚](#1-ç®—åŠ›è¦æ±‚)
    - [2. åŸºäº transformers ä½¿ç”¨æ¨¡å‹](#2-åŸºäº-transformers-ä½¿ç”¨æ¨¡å‹)
    - [3. åŸºäº LMDeploy é«˜æ€§èƒ½éƒ¨ç½²](#3-åŸºäº-lmdeploy-é«˜æ€§èƒ½éƒ¨ç½²)
  - [ğŸ“’ æ•°æ®æ„å»º](#-æ•°æ®æ„å»º)
  - [ğŸ”§ è®­ç»ƒæŒ‡å—](#-è®­ç»ƒæŒ‡å—)
  - [ğŸ“š åº”ç”¨ä½“éªŒ](#-åº”ç”¨ä½“éªŒ)
  - [ğŸ–ï¸ è‡´è°¢](#%EF%B8%8F-è‡´è°¢)
  - [å¼€æºè®¸å¯è¯](#å¼€æºè®¸å¯è¯)



## ğŸ“„ æ¶æ„å›¾

<div align="center">
  <img src="../assets/Magic_llava.drawio.png" width="1000"/>
</div>



## ğŸ‰ News



## ğŸ“ ç®€ä»‹

**Magic_LLaVA** æ˜¯ä¸€ä¸ªåœ¨ç»å…¸ LLaVA æ¶æ„ä¸Šè¿›è¡Œæ”¹è¿›å¹¶è®­ç»ƒï¼Œæ—¨åœ¨ä»å¤šå¼ èŠå¤©æˆªå›¾ä¸­æå–æ³•å¾‹äº‹å®ä½œä¸ºæ³•å¾‹å‡­è¯ï¼Œä»¥æ­¤æ¥å›ç­”ç”¨æˆ·æå‡ºçš„å„ç§æ³•å¾‹é—®é¢˜çš„å¤šæ¨¡æ€å¤§æ¨¡å‹ã€‚åŒæ—¶ï¼Œåº”ç”¨æ”¯æŒ RAG æ£€ç´¢æ³•å¾‹çŸ¥è¯†ä»¥è¿›è¡Œä¸“ä¸šçš„çŸ¥è¯†è¡¥å……ï¼Œè®©å…¶æ›´ç²¾å‡†åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

Magic_LLaVA ç»è¿‡äº†å¤§é‡ OCR-textã€æ–‡æ¡£ã€è¡¨å•æ•°æ®é›†çš„è®­ç»ƒï¼Œåœ¨æœ‰å…³æ–‡æ¡£è¯†åˆ«çš„èƒ½åŠ›ä¸Šæœ‰äº†å¤§å¹…çš„æå‡ï¼ŒåŒæ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä»£ç ã€æ•°å­¦æ•°æ®é›†å¢å¼ºæ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œå¹¶åœ¨æ³•å¾‹ä¸“ä¸šçŸ¥è¯†æ•°æ®é›†ä¸Šè¿›è¡Œç»§ç»­é¢„è®­ç»ƒä½¿æ¨¡å‹è·å¾—äº†æ³•å¾‹ç›¸å…³çŸ¥è¯†ã€‚

**å¦‚æœä½ è§‰å¾—æœ¬é¡¹ç›®æœ‰å¸®åŠ©çš„è¯ï¼Œæ¬¢è¿starï½â­**



## ğŸ“Œ å¿«é€Ÿå¼€å§‹

### 1. ç®—åŠ›è¦æ±‚

- ä½¿ç”¨æ¨¡å‹è¿›è¡Œæ¨ç†è‡³å°‘éœ€è¦8Gæ˜¾å­˜



### 2. åŸºäº transformers ä½¿ç”¨æ¨¡å‹

```python
from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration
import torch
from PIL import Image
import requests

processor = LlavaNextProcessor.from_pretrained("magic_llava")

model = LlavaNextForConditionalGeneration.from_pretrained("magic_llava", torch_dtype=torch.float16, low_cpu_mem_usage=True) 
model.to("cuda:0")

url = "https://github.com/haotian-liu/LLaVA/blob/1a91fc274d7c35a9b50b3cb29c4247ae5837ce39/images/llava_v1_5_radar.jpg?raw=true"
image = Image.open(requests.get(url, stream=True).raw)
prompt = "[INST] <image>\nWhat is shown in this image? [/INST]"

inputs = processor(prompt, image, return_tensors="pt").to("cuda:0")

output = model.generate(**inputs, max_new_tokens=100)

print(processor.decode(output[0], skip_special_tokens=True))

```



### 3. åŸºäº lmdeploy é«˜æ€§èƒ½éƒ¨ç½²

```shell
# ä½¿ç”¨å‘½ä»¤è¡Œ
lmdeploy serve api_server /root/model/magic_llava  --model-name internvl-internlm2 --server-port 23333
```



## ğŸ“’ æ•°æ®æ„å»º

- è¯¦æƒ…è¯·è§[æ•°æ®æ„å»º](./datasets/README.md)



## ğŸ”§ è®­ç»ƒæŒ‡å—

- è¯¦æƒ…è¯·è§[è®­ç»ƒæŒ‡å—](./train/README.md)



## ğŸ“š åº”ç”¨ä½“éªŒ

- åº”ç”¨éƒ¨ç½²åœ¨ [OpenXLab åº”ç”¨ä¸­å¿ƒ](https://openxlab.org.cn/apps/detail/Nobody-ML/Magic_LLaVA)ï¼Œå¯å‰å¾€ä½“éªŒ



## ğŸ–ï¸ è‡´è°¢

- [OpenXLab](https://openxlab.org.cn/home)
- [InternLM](https://github.com/InternLM/InternLM/tree/main)

## å¼€æºè®¸å¯è¯

è¯¥é¡¹ç›®é‡‡ç”¨ [AGPL-3.0 licenseå¼€æºè®¸å¯è¯](LICENSE)ã€‚åŒæ—¶ï¼Œè¯·éµå®ˆæ‰€ä½¿ç”¨çš„æ¨¡å‹ä¸æ•°æ®é›†çš„è®¸å¯è¯ã€‚
